{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/cosmo-xl\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/cosmo-xl\").to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'statement'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flan_breakdown import flan_breakdown \n",
    "flan_breakdown(input(\"Enter a sentence: \"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_input(situation_narrative, role_instruction, conversation_history):\n",
    "    input_text = \" <turn> \".join(conversation_history)\n",
    "\n",
    "    if role_instruction != \"\":\n",
    "        input_text = \"{} <sep> {}\".format(role_instruction, input_text)\n",
    "\n",
    "    if situation_narrative != \"\":\n",
    "        input_text = \"{} <sep> {}\".format(situation_narrative, input_text)\n",
    "\n",
    "    return input_text\n",
    "\n",
    "def generate(situation_narrative=\"\", role_instruction=\"\", conversation_history=\"\"):\n",
    "    \"\"\"\n",
    "    situation_narrative: the description of situation/context with the characters included (e.g., \"David goes to an amusement park\")\n",
    "    role_instruction: the perspective/speaker instruction (e.g., \"Imagine you are David and speak to his friend Sarah\").\n",
    "    conversation_history: the previous utterances in the conversation in a list\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = set_input(situation_narrative, role_instruction, conversation_history)+ \" <sep> Companion Core:\"\n",
    "    inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=128, temperature=1.0, top_p=.95, do_sample=True)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    return response\n",
    "names = \"Brayden\"\n",
    "convo_duration = \"12.07 minutes\"\n",
    "instruction = f\"You are the Companion Core. You are a robotic assistant created by Brayden Levangie. You are equipped with the ability to browse the internet and understand your surroundings. You strive to provide accurate and truthful information. You are currently talking with {names}, and this conversation has been going on for {convo_duration}\"\n",
    "conversation = [\n",
    "    \"Brayden: Hey, do you know who I am?\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
